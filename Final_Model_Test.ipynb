{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc247b72-fb43-466d-ab4e-32dba1a8c74d",
      "metadata": {
        "id": "cc247b72-fb43-466d-ab4e-32dba1a8c74d"
      },
      "source": [
        "### Library and Data Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229dbd95-aa82-478a-83ac-b8f203fa60f8",
      "metadata": {
        "id": "229dbd95-aa82-478a-83ac-b8f203fa60f8"
      },
      "outputs": [],
      "source": [
        "!pip install skorch torch scikit-learn\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    precision_recall_curve,\n",
        "    accuracy_score,\n",
        "    log_loss,\n",
        "    PrecisionRecallDisplay,\n",
        "    make_scorer,\n",
        "    RocCurveDisplay\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, average_precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import seaborn as sns\n",
        "import imblearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import shap\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from xgboost import cv\n",
        "from xgboost import XGBClassifier\n",
        "from skorch.callbacks import EarlyStopping, Checkpoint, EpochScoring\n",
        "from skorch.helper import predefined_split\n",
        "from sklearn.base import BaseEstimator\n",
        "from skorch.callbacks import EarlyStopping, Checkpoint, EpochScoring\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id_1 = '18c5DynpKSiey55WdTBkNE7Iwb7l_HL-k'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_1}', 'data2011.csv', quiet=False)\n",
        "df1 = pd.read_csv('data2011.csv')\n",
        "\n",
        "file_id_2 = '1bJsC9bUmrMHXlKIv82Gkl-Qxldy9D-KQ'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_2}', 'data2102.csv', quiet=False)\n",
        "df2 = pd.read_csv('data2102.csv')\n",
        "\n",
        "file_id_3 = '1BU41bihK6rCTVWmyUFr4gEmYwIclKeMD'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_3}', 'data2105.csv', quiet=False)\n",
        "df3 = pd.read_csv('data2105.csv')\n",
        "\n",
        "file_id_4 = '1VUA3AgnL7ouqCY3vrui7G6qr5RbbJwDQ'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_4}', 'data2108.csv', quiet=False)\n",
        "df4 = pd.read_csv('data2108.csv')\n",
        "\n",
        "file_id_5 = '1GSL8AOlv9fWylFU-HAKbIbOCxuN1b754'\n",
        "gdown.download(f'https://drive.google.com/uc?id={file_id_5}', 'data2111.csv', quiet=False)\n",
        "df5 = pd.read_csv('data2111.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2xO9N6dCt2vk"
      },
      "id": "2xO9N6dCt2vk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3NlTMLK9Zjn3",
      "metadata": {
        "id": "3NlTMLK9Zjn3"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58751aed-cbed-44aa-92d6-565354ffb93d",
      "metadata": {
        "id": "58751aed-cbed-44aa-92d6-565354ffb93d"
      },
      "outputs": [],
      "source": [
        "## Rename Columns\n",
        "def rename(df):\n",
        "    return df.rename(columns={\n",
        "        'RREL16': 'primary_income',\n",
        "        'RREL13': 'employment_status',\n",
        "        'RREL27': 'loan_purpose',\n",
        "        'RREL25': 'original_term',\n",
        "        'RREL30': 'current_balance',\n",
        "        'RREL29': 'original_balance',\n",
        "        'RREL43': 'current_interest_rate',\n",
        "        'RREL42': 'interest_type',\n",
        "        'RREL69': 'account_status',\n",
        "        'RREL39': 'payment_due',\n",
        "        'RREL67': 'arrears_balance',\n",
        "        'RREL68': 'days_in_arrears',\n",
        "        'RREL71': 'default_amount',\n",
        "        'RREC6': 'collateral_region',\n",
        "        'RREC7': 'occupancy_type',\n",
        "        'RREC9': 'property_type',\n",
        "        'RREC16': 'original_ltv',\n",
        "        'RREC17': 'original_valuation',\n",
        "        'RREC12': 'current_ltv',\n",
        "        'RREC13': 'current_valuation',\n",
        "        'age': 'age',\n",
        "        'PrepaymentFee': 'prepayment_fee',\n",
        "        'PrepaymentHistory': 'prepayment_history',\n",
        "        'RREL30_t_1': 'past_balance',\n",
        "        'RREL39_t_1': 'past_payment_due',\n",
        "        'RREL43_t_1': 'past_interest_rate',\n",
        "        'RREC12_t_1': 'past_ltv',\n",
        "        'RREC13_t_1': 'past_valuation',\n",
        "        'incentive': 'incentive',\n",
        "        'target': 'target'\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f56af3df-339d-440b-b19e-1051935ca159",
      "metadata": {
        "id": "f56af3df-339d-440b-b19e-1051935ca159"
      },
      "outputs": [],
      "source": [
        "## Embed Categorical columns\n",
        "def embed(df):\n",
        "    df['employment_status'] = df['employment_status'].astype('category')\n",
        "    df['loan_purpose'] = df['loan_purpose'].astype('category')\n",
        "    df['collateral_region'] = df['collateral_region'].astype('category')\n",
        "    df['occupancy_type'] = df['occupancy_type'].astype('category')\n",
        "    df['property_type'] = df['property_type'].astype('category')\n",
        "    df['interest_type'] = df['interest_type'].astype('category')\n",
        "    df['account_status'] = df['account_status'].astype('category')\n",
        "    df['prepayment_fee'] = df['prepayment_fee'].astype('category')\n",
        "    df['prepayment_history'] = df['prepayment_history'].astype('category')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename and embed all datasets\n",
        "df2 = rename(df2)\n",
        "df2 = embed(df2)\n",
        "df3 = rename(df3)\n",
        "df3 = embed(df3)\n",
        "df4 = rename(df4)\n",
        "df4 = embed(df4)\n",
        "df5 = rename(df5)\n",
        "df5 = embed(df5)"
      ],
      "metadata": {
        "id": "EHP7FES5t-FZ"
      },
      "id": "EHP7FES5t-FZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data from targets\n",
        "X1_train = df1.drop('target', axis = 1)\n",
        "y1_train = df1['target']\n",
        "\n",
        "X2_train = df2.drop('target', axis = 1)\n",
        "y2_train = df2['target']\n",
        "\n",
        "X3_train = df3.drop('target', axis = 1)\n",
        "y3_train = df3['target']\n",
        "\n",
        "X4_train = df4.drop('target', axis = 1)\n",
        "y4_train = df4['target']\n",
        "\n",
        "X5_test = df5.drop('target', axis = 1)\n",
        "y5_test = df5['target']"
      ],
      "metadata": {
        "id": "KRWZGOPCakHo"
      },
      "id": "KRWZGOPCakHo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training data from first four datasets\n",
        "X_train = pd.concat([X1_train, X2_train, X3_train, X4_train], ignore_index=True)\n",
        "y_train = pd.concat([y1_train, y2_train, y3_train, y4_train], ignore_index=True)"
      ],
      "metadata": {
        "id": "RDzkOpLducZH"
      },
      "id": "RDzkOpLducZH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Model Test"
      ],
      "metadata": {
        "id": "W3AKFK3buPk5"
      },
      "id": "W3AKFK3buPk5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced XGBoost with comprehensive tuning for imbalanced data\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'reg_alpha': [0, 0.1, 1],\n",
        "    'reg_lambda': [0, 1, 10],\n",
        "    'scale_pos_weight': [50, 100],\n",
        "    'n_estimators': [1000, 2000, 4000, 8000]\n",
        "}\n",
        "\n",
        "# Set up XGBoost without early stopping in the initializer\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    eval_metric=['aucpr', 'logloss'],\n",
        "    enable_categorical=True,\n",
        "    use_label_encoder=False,\n",
        "    verbosity=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 5-Fold Stratified Cross Validation\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Custom scoring for imbalanced data\n",
        "scoring = {\n",
        "    'precision': make_scorer(precision_score, zero_division=0),\n",
        "    'recall': make_scorer(recall_score, zero_division=0),\n",
        "    'f1': make_scorer(f1_score, zero_division=0),\n",
        "    'aucpr': 'average_precision'\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV\n",
        "grid = RandomizedSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=30,  # Reduced for faster execution\n",
        "    scoring=scoring,\n",
        "    refit='aucpr',\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Fit without early stopping in grid search\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# Now train final model using best params\n",
        "best_params = grid.best_params_.copy()\n",
        "\n",
        "\n",
        "final_model = xgb.XGBClassifier(\n",
        "    **best_params,\n",
        "    objective='binary:logistic',\n",
        "    eval_metric=['aucpr', 'logloss'],\n",
        "    early_stopping_rounds=50,\n",
        "    enable_categorical=True,\n",
        "    use_label_encoder=False,\n",
        "    verbosity=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Now apply early stopping\n",
        "final_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X5_test, y5_test)],\n",
        "    verbose=True\n",
        ")\n",
        "# Best model\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "\n",
        "# Evaluate on test set with optimal threshold\n",
        "y_proba = final_model.predict_proba(X5_test)[:, 1]\n",
        "\n",
        "# Find optimal threshold\n",
        "precision, recall, thresholds = precision_recall_curve(y5_test, y_proba)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
        "optimal_idx = np.argmax(f1_scores)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "y_pred = (y_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "# Metrics\n",
        "print(f\"\\nOptimal Threshold: {optimal_threshold:.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y5_test, y_pred)}\")\n",
        "print(f\"Precision: {precision_score(y5_test, y_pred, zero_division=0):.4f}\")\n",
        "print(f\"Recall:    {recall_score(y5_test, y_pred, zero_division=0):.4f}\")\n",
        "print(f\"F1 Score:  {f1_score(y5_test, y_pred, zero_division=0):.4f}\")\n",
        "print(f\"ROC AUC:   {roc_auc_score(y5_test, y_proba):.4f}\")\n",
        "print(f\"PR AUC:    {average_precision_score(y5_test, y_proba):.4f}\")\n",
        "\n",
        "# ROC Curve (new addition)\n",
        "plt.figure(figsize=(8, 6))\n",
        "RocCurveDisplay.from_estimator(final_model, X5_test, y5_test)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=12, pad=20)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.legend(loc='lower right', fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve (legend moved)\n",
        "plt.figure(figsize=(8, 6))\n",
        "disp = PrecisionRecallDisplay.from_estimator(final_model, X5_test, y5_test)\n",
        "plt.title('Precision-Recall Curve', fontsize=12, pad=20)\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Move the legend to upper right (no new legend created)\n",
        "plt.legend(loc='upper right', bbox_to_anchor=(0.95, 0.95), framealpha=1)\n",
        "\n",
        "# 3. Learning curves (with download)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(results['validation_0']['logloss'], label='Test Log Loss', color='#1f77b4')\n",
        "plt.plot(results['validation_0']['aucpr'], label='Test AUC-PR', color='#ff7f0e')\n",
        "plt.xlabel('Iterations', fontsize=10)\n",
        "plt.ylabel('Metric Value', fontsize=10)\n",
        "plt.title('Learning Curves', fontsize=12, pad=20)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)"
      ],
      "metadata": {
        "id": "-aHGMuef9ulp"
      },
      "id": "-aHGMuef9ulp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cc247b72-fb43-466d-ab4e-32dba1a8c74d",
        "3NlTMLK9Zjn3",
        "J7z2pB-VZuD4",
        "779b217c-588f-4f6a-8f92-84f88972bf8d",
        "cd9da318-ff79-49b1-9688-d8575867d92d",
        "a65abde5-2e5a-4296-b45d-be214ea9fb20",
        "8yrGbPycSHN_",
        "ac97abc9-bfb1-4f3e-8ad4-4e06dad31b42",
        "dYSlMe3xZDk6",
        "uGL2zf9RrEHW",
        "-Jh86QF3vf0E",
        "p9_zyXE7xI-v",
        "IoVqpncXjZvc",
        "V9X3ZrqrmKfw",
        "RcGQH1M0Gt21",
        "aNcHmWHlrQfg",
        "qIxcQu1etIvO",
        "j0MG7mGAHAyE",
        "SmMMIAXlHJc-",
        "wTvIpcrTH-gY",
        "Fw-MNcDYT4Qg",
        "6NKa-erwYK6f",
        "gMTszNDJcN1V",
        "XXPcnXi_m_H_",
        "-GuQRZNt1qS0",
        "PR_4Ztf2mm0-",
        "NSti2uLumqWm"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}